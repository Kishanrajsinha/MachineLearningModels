{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.7832891 , -0.25466046, -0.18001091, -0.14280869, -0.45246306,\n",
       "        -0.04055174, -0.15085216,  0.20873149,  0.55088365,  0.49127626]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1866881 , 0.06612122, 0.07124604, 0.07394648, 0.05425457,\n",
       "        0.08190815, 0.07335407, 0.10509679, 0.1479736 , 0.13941102]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5021567"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2970 - accuracy: 0.9129\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1466 - accuracy: 0.9570\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1100 - accuracy: 0.9666\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0892 - accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0758 - accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0662 - accuracy: 0.9785\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0602 - accuracy: 0.9804\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0538 - accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0501 - accuracy: 0.9839\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0454 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c32cbb080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0732 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07322956069997745, 0.9782]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.9939790e-09, 7.7488684e-12, 1.8510468e-09, 2.4217136e-06,\n",
       "        1.4658569e-14, 1.9371869e-07, 3.7537602e-16, 9.9999702e-01,\n",
       "        4.6204068e-10, 4.0002294e-07],\n",
       "       [1.0912172e-08, 7.2492780e-06, 9.9999273e-01, 2.3608322e-09,\n",
       "        8.3744573e-17, 1.6580133e-10, 1.3699601e-11, 4.1559606e-19,\n",
       "        2.8453886e-09, 5.1547355e-15],\n",
       "       [3.3568970e-10, 9.9996066e-01, 1.1340940e-06, 1.8151317e-07,\n",
       "        4.5511152e-07, 3.1775887e-08, 5.1361656e-07, 1.3926419e-05,\n",
       "        2.2968119e-05, 4.2624286e-08],\n",
       "       [9.9998748e-01, 4.1151302e-10, 1.0759893e-05, 5.5494533e-09,\n",
       "        4.3393888e-09, 9.4874201e-07, 2.2430524e-07, 2.7931509e-07,\n",
       "        7.1673695e-11, 3.5534967e-07],\n",
       "       [6.7671806e-09, 5.7206904e-12, 1.4518436e-07, 9.8906765e-11,\n",
       "        9.9745387e-01, 4.9127301e-08, 1.8839152e-09, 2.7330467e-05,\n",
       "        5.7939790e-08, 2.5186595e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
